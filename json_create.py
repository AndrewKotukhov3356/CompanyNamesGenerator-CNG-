# -*- coding: utf-8 -*-
"""Json_create.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IQ2DjtzSR1bDM9oFEJZFHvO0kdP7qUy9
"""

#Please install needed libraries below!

!pip install rusyll
!pip install markovify==0.8.3

#Please import needed libraries below!

from rusyll import rusyll
from markovify import Chain
from enum import Enum, unique

import markovify
import json

# Json creator function:


def main(input_file, output_file):
    corpus = []
    lines_processed = 0

    for line in input_file:
        lines_processed += 1
        try:
            corpus.append(
                rusyll.word_to_syllables_safe_wd(
                    line.strip().lower()))
        except AssertionError:
            pass

    chain = Chain(corpus, 1)
    with open(output_file, 'w+') as f:
        f.write(chain.to_json())

# Empty txt file creator function:


def create_empty_txt(txtfile, mode):
    with open(txtfile, mode) as jell:
        jell = open(txtfile, mode)
    return jell

# Opening our TF-IDF sorted files:

# NOUNS:
n = open('nouns.txt', 'r').readlines()

# ADJECTIVES:
a = open('adjf.txt', 'r').readlines()

# Creating json files for each txt file using our main function:

# NOUNS:
main(n, 'nouns.json')

# ADJECTIVES:
main(a, 'adjf.json')

# Class of types we will use:

class WordTypes(Enum):
    NOUN = "Существительное"
    ADJECTIVE = "Прилагательное"

# Main class to create magic words:

class WordMaker:
    def __init__(self, json_file) -> None:  # Markov chain function.
        self.chains = {}
        for wtype in WordTypes:
            self.chains[wtype] = markovify.Chain.from_json(json_file)

    # Producing words from created markov chain.
    def make_a_word(
            self,
            word_type: WordTypes,
            attempts: int = 100) -> str:
        for _ in range(attempts):
            word = "".join(self.chains[word_type].walk())
            if len(word) > 3:
                return word
        raise ValueError("Error!!!")

# Opening json files:
f = open('nouns.json')
h = open('adjf.json')
json_file1 = json.load(f)
json_file2 = json.load(h)

# Please RUN this cell, it will create magic nouns.

# Sending to our class with nouns.json file:
emp = WordMaker(json_file1)

# Creating nouns:
k = 10000
j = create_empty_txt('nounsfinal.txt', 'w')
while k != 0:
    if(emp.make_a_word(WordTypes.NOUN, 500) not in n):
        print(emp.make_a_word(WordTypes.NOUN, 500), file=j)
        k -= 1

# Please RUN this cell, it will create magic adjectives.

# Sending to our class with adjf.json file:
emp = WordMaker(json_file2)

# Creating adjectives:
k = 10000
j = create_empty_txt('adjffinal.txt', 'w')
while k != 0:
    if(emp.make_a_word(WordTypes.ADJECTIVE, 500) not in n):
        print(emp.make_a_word(WordTypes.ADJECTIVE, 500), file=j)
        k -= 1

